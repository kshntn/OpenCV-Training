{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Table of Content</font>\n",
    "\n",
    "- [Step 1: Understand Your Problem](#step1)\n",
    "- [Step 2: Get the Data](#step2)\n",
    "- [Step 3. Data Preparation](#step3)\n",
    "- [Step 4: Train a Simple Model](#step4)\n",
    "- [Step 5: Sample Prediction](#step5)\n",
    "- [Step 6. Display Mistakes](#step6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Project 1 - Part 2: Train an Image Classifier From Scratch</font>\n",
    "As discussed in the previous notebook, the steps for training Neural Networks are:\n",
    "\n",
    "- Step 1 - Understand your problem\n",
    "- Step 2A - Get the data\n",
    "- Step 2B - Explore and understand your data\n",
    "- Step 2C - Create a sample data from the dataset\n",
    "- Step 3 - Data preparation\n",
    "- Step 4 - Train a simple model on sample data and check the pipeline before proceeding to train the full network\n",
    "- Step 5 - Train on full data\n",
    "- Step 6 - Improve your model\n",
    "\n",
    "You have already been through Steps `1-4` in the previous notebook. Use them here as well.\n",
    "\n",
    "Here, you will implement Steps `5` & `6` from scratch. Design a model that achieves `>=85%` validation accuracy on the given dataset.\n",
    "\n",
    "There are 70 points for this notebook. The sections which carry marks are in Red.\n",
    "\n",
    "There are **70 points** for this notebook. <font style=\"color:red\">The sections which carry marks are in Red.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GPU compute you can use Kaggle Kernels, Google Colab or any other service of your choice.\n",
    "\n",
    "After completing the assignment, upload and submit it on the portal for feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:red\">Use the full data to train the network. You need to achieve 85% accuracy for validation data to successfully complete this assignment.</font>\n",
    "\n",
    "\n",
    "<font style=\"color:red\">Just remember to build your own model, not use any pre-trained models/weights.</font>\n",
    "\n",
    "\n",
    "Upon completing the assignment, <font style=\"color:red\">upload the notebook and the models folder on the portal for  feedback.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Step 1: Understand Your problem </font><a name=\"step1\"></a>\n",
    "Already covered in the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Step 2: Get the Data </font><a name=\"step2\"></a>\n",
    "\n",
    "Already covered in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://www.dropbox.com/sh/n5nya3g3airlub6/AACi7vaUjdTA0t2j_iKWgp4Ra?dl=1\" -O data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">Extract the Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Step 3. Data Preparation</font><a name=\"step3\"></a>\n",
    "Already covered in the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">3.1. Import Libraries </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from typing import Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">3.2.1. Compulsary Preprocessing Transforms</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess_transforms():\n",
    "    \n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    return preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">3.2.2. Common Image Transforms</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_common_transforms(mean=(0.4611, 0.4359, 0.3905), std=(0.2193, 0.2150, 0.2109)):\n",
    "    preprocess = image_preprocess_transforms()\n",
    "    \n",
    "    common_transforms = transforms.Compose([\n",
    "        preprocess,\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    return common_transforms\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">3.2.3. Mean and STD</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(data_root, num_workers=4):\n",
    "    \n",
    "    transform = image_preprocess_transforms()\n",
    "    \n",
    "    loader = data_loader(data_root, transform)\n",
    "    \n",
    "    batch_mean = torch.zeros(3)\n",
    "    batch_mean_sqrd = torch.zeros(3)\n",
    "    \n",
    "    for batch_data, _ in loader:\n",
    "        batch_mean += batch_data.mean(dim=(0, 2, 3)) # E[batch_i] \n",
    "        batch_mean_sqrd += (batch_data ** 2).mean(dim=(0, 2, 3)) #  E[batch_i**2]\n",
    "    \n",
    "    # E[dataset] = E[E[batch_1], E[batch_2], ...]\n",
    "    mean = batch_mean / len(loader)\n",
    "    \n",
    "    # var[X] = E[X**2] - E[X]**2\n",
    "    \n",
    "    # E[X**2] = E[E[batch_1**2], E[batch_2**2], ...]\n",
    "    # E[X]**2 = E[E[batch_1], E[batch_2], ...] ** 2\n",
    "    \n",
    "    var = (batch_mean_sqrd / len(loader)) - (mean ** 2)\n",
    "        \n",
    "    std = var ** 0.5\n",
    "    print('mean: {}, std: {}'.format(mean, std))\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">3.3. Data Loaders </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">3.3.1. Data Loader for Full Data</font>\n",
    "Data loader for generating batches of data to be used by the training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(data_root, transform, batch_size=16, shuffle=False, num_workers=2):\n",
    "    dataset = datasets.ImageFolder(root=data_root, transform=transform)\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         num_workers=num_workers,\n",
    "                                         shuffle=shuffle)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">3.4. Prepare Data</font>\n",
    "The main function which uses all the above functions to generate the train and test dataloaders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, data_root, num_workers=4, data_augmentation=False):\n",
    "#     YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Step 4: Train Your Model</font><a name=\"step4\"></a>\n",
    "\n",
    "Now, create the training pipeline, and train your model on the full data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:red\">4.1. Configurations [20 Points]</font>\n",
    "\n",
    "To achieve good results, change the parameters given in these configurations. Score 20 points for all right choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">4.1.1. System Configuration</font>\n",
    "\n",
    "Fix the seed (e.g., `21`) to get a reproducible result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    '''\n",
    "    Describes the common system setting needed for reproducible training\n",
    "    '''\n",
    "    seed: int = 21  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">4.1.2. Training Configuration</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 10 \n",
    "    epochs_count: int = 50  \n",
    "    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n",
    "    log_interval: int = 5  \n",
    "    test_interval: int = 1  \n",
    "    data_root: str = \"./cat-dog-panda\" \n",
    "    num_workers: int = 2  \n",
    "    device: str = 'cuda'  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">4.1.3. System Setup</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_system(system_config: SystemConfiguration) -> None:\n",
    "    torch.manual_seed(system_config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
    "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">4.2. Training Function</font>\n",
    "\n",
    "You are already familiar with the training function. No changes needed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "    train_loader: torch.utils.data.DataLoader, epoch_idx: int\n",
    ") -> None:\n",
    "    \n",
    "    # change model in training mood\n",
    "    model.train()\n",
    "    \n",
    "    # to get batch loss\n",
    "    batch_loss = np.array([])\n",
    "    \n",
    "    # to get batch accuracy\n",
    "    batch_acc = np.array([])\n",
    "        \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # clone target\n",
    "        indx_target = target.clone()\n",
    "        # send data to device (its is medatory if GPU has to be used)\n",
    "        data = data.to(train_config.device)\n",
    "        # send target to device\n",
    "        target = target.to(train_config.device)\n",
    "\n",
    "        # reset parameters gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # cross entropy loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # find gradients w.r.t training parameters\n",
    "        loss.backward()\n",
    "        # Update parameters using gardients\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = np.append(batch_loss, [loss.item()])\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "            \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]  \n",
    "                        \n",
    "        # correct prediction\n",
    "        correct = pred.cpu().eq(indx_target).sum()\n",
    "            \n",
    "        # accuracy\n",
    "        acc = float(correct) / float(len(data))\n",
    "        \n",
    "        batch_acc = np.append(batch_acc, [acc])\n",
    "            \n",
    "    epoch_loss = batch_loss.mean()\n",
    "    epoch_acc = batch_acc.mean()\n",
    "    print('Epoch: {} \\nTrain Loss: {:.6f} Acc: {:.4f}'.format(epoch_idx, epoch_loss, epoch_acc))\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">4.3. Validation Function</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    train_config: TrainingConfiguration,\n",
    "    model: nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    # \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    count_corect_predictions = 0\n",
    "    for data, target in test_loader:\n",
    "        indx_target = target.clone()\n",
    "        data = data.to(train_config.device)\n",
    "        \n",
    "        target = target.to(train_config.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        \n",
    "        # add loss for each mini batch\n",
    "        test_loss += F.cross_entropy(output, target).item()\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1] \n",
    "        \n",
    "        # add correct prediction count\n",
    "        count_corect_predictions += pred.cpu().eq(indx_target).sum()\n",
    "\n",
    "    # average over number of mini-batches\n",
    "    test_loss = test_loss / len(test_loader)  \n",
    "    \n",
    "    # average over number of dataset\n",
    "    accuracy = 100. * count_corect_predictions / len(test_loader.dataset)\n",
    "    \n",
    "    print(\n",
    "        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, count_corect_predictions, len(test_loader.dataset), accuracy\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return test_loss, accuracy/100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">4.4. Save the Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, device, model_dir='models', model_file_name='cat_dog_panda_classifier.pt'):\n",
    "    \n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # make sure you transfer the model to cpu.\n",
    "    if device == 'cuda':\n",
    "        model.to('cpu')\n",
    "\n",
    "    # save the state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        model.to('cuda')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">4.5. Load the Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_dir='models', model_file_name='cat_dog_panda_classifier.pt'):\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # loading the model and getting model parameters by using load_state_dict\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">4.6. Main Function for Training</font>\n",
    "\n",
    "Note: Before calling the train function, we calculate the validation loss, which we know should be close to $\\log(\\text{num_classes})$. Also, the accuracy should be close to $\\frac{1}{\\text{num_classes}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, optimizer, scheduler=None, system_configuration=SystemConfiguration(), \n",
    "         training_configuration=TrainingConfiguration(), data_augmentation=True):\n",
    "    \n",
    "    # system configuration\n",
    "    setup_system(system_configuration)\n",
    "\n",
    "    # batch size\n",
    "    batch_size_to_set = training_configuration.batch_size\n",
    "    # num_workers\n",
    "    num_workers_to_set = training_configuration.num_workers\n",
    "    # epochs\n",
    "    epoch_num_to_set = training_configuration.epochs_count\n",
    "\n",
    "    # if GPU is available use training config, \n",
    "    # else lowers batch_size, num_workers and epochs count\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        batch_size_to_set = 16\n",
    "        num_workers_to_set = 4\n",
    "\n",
    "    # data loader\n",
    "    train_loader, test_loader = get_data(\n",
    "        batch_size=batch_size_to_set,\n",
    "        data_root=training_configuration.data_root,\n",
    "        num_workers=num_workers_to_set,\n",
    "        data_augmentation=data_augmentation\n",
    "    )\n",
    "    \n",
    "    # Update training configuration\n",
    "    training_configuration = TrainingConfiguration(\n",
    "        device=device,\n",
    "        batch_size=batch_size_to_set,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "        \n",
    "    # send model to device (GPU/CPU)\n",
    "    model.to(training_configuration.device)\n",
    "\n",
    "    best_loss = torch.tensor(np.inf)\n",
    "    \n",
    "    # epoch train/test loss\n",
    "    epoch_train_loss = np.array([])\n",
    "    epoch_test_loss = np.array([])\n",
    "    \n",
    "    # epch train/test accuracy\n",
    "    epoch_train_acc = np.array([])\n",
    "    epoch_test_acc = np.array([])\n",
    "    \n",
    "    # Calculate Initial Test Loss\n",
    "    init_val_loss, init_val_accuracy = validate(training_configuration, model, test_loader)\n",
    "    print(\"Initial Test Loss : {:.6f}, \\nInitial Test Accuracy : {:.3f}%\\n\".format(init_val_loss, \n",
    "                                                                                   init_val_accuracy*100))\n",
    "    \n",
    "    # trainig time measurement\n",
    "    t_begin = time.time()\n",
    "    for epoch in range(training_configuration.epochs_count):\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch)\n",
    "        \n",
    "        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n",
    "        \n",
    "        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n",
    "\n",
    "        elapsed_time = time.time() - t_begin\n",
    "        speed_epoch = elapsed_time / (epoch + 1)\n",
    "        speed_batch = speed_epoch / len(train_loader)\n",
    "        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n",
    "        \n",
    "        print(\n",
    "            \"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(\n",
    "                elapsed_time, speed_epoch, speed_batch, eta\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Validate\n",
    "        if epoch % training_configuration.test_interval == 0:\n",
    "            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n",
    "            \n",
    "            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n",
    "        \n",
    "            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n",
    "            \n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "                print('Model Improved. Saving the Model...\\n')\n",
    "                save_model(model, device=training_configuration.device)\n",
    "        \n",
    "                \n",
    "    print(\"Total time: {:.2f}, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss))\n",
    "    \n",
    "    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">4.7. Plot Loss and Accuracy</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(train_loss, val_loss, train_acc, val_acc, colors, \n",
    "                       loss_legend_loc='upper center', acc_legend_loc='upper left', \n",
    "                       fig_size=(20, 10), sub_plot1=(1, 2, 1), sub_plot2=(1, 2, 2)):\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.subplot(sub_plot1[0], sub_plot1[1], sub_plot1[2])\n",
    "    \n",
    "    for i in range(len(train_loss)):\n",
    "        x_train = range(len(train_loss[i]))\n",
    "        x_val = range(len(val_loss[i]))\n",
    "        \n",
    "        min_train_loss = train_loss[i].min()\n",
    "        \n",
    "        min_val_loss = val_loss[i].min()\n",
    "        \n",
    "        plt.plot(x_train, train_loss[i], linestyle='-', color='tab:{}'.format(colors[i]), \n",
    "                 label=\"TRAIN LOSS ({0:.4})\".format(min_train_loss))\n",
    "        plt.plot(x_val, val_loss[i], linestyle='--' , color='tab:{}'.format(colors[i]), \n",
    "                 label=\"VALID LOSS ({0:.4})\".format(min_val_loss))\n",
    "        \n",
    "    plt.xlabel('epoch no.')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc=loss_legend_loc)\n",
    "    plt.title('Training and Validation Loss')\n",
    "        \n",
    "    plt.subplot(sub_plot2[0], sub_plot2[1], sub_plot2[2])\n",
    "    \n",
    "    for i in range(len(train_acc)):\n",
    "        x_train = range(len(train_acc[i]))\n",
    "        x_val = range(len(val_acc[i]))\n",
    "        \n",
    "        max_train_acc = train_acc[i].max() \n",
    "        \n",
    "        max_val_acc = val_acc[i].max() \n",
    "        \n",
    "        plt.plot(x_train, train_acc[i], linestyle='-', color='tab:{}'.format(colors[i]), \n",
    "                 label=\"TRAIN ACC ({0:.4})\".format(max_train_acc))\n",
    "        plt.plot(x_val, val_acc[i], linestyle='--' , color='tab:{}'.format(colors[i]), \n",
    "                 label=\"VALID ACC ({0:.4})\".format(max_val_acc))\n",
    "        \n",
    "    plt.xlabel('epoch no.')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc=acc_legend_loc)\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    \n",
    "    fig.savefig('sample_loss_acc_plot.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:red\">4.8. Define Model [20 Points]</font>\n",
    "\n",
    "Next, define the CNN model. Keep iterating. Do this by training various models. Just ,change the :\n",
    "    \n",
    "- number of layers\n",
    "- parameters inside the layers\n",
    "- different types of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "#     YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:red\">4.9. Training [20 Points]</font>\n",
    "\n",
    "Experiment with:\n",
    "\n",
    "- Optimizers and learning rate schedulers \\[You can  get good results even without a learning rate scheduler\\]\n",
    "\n",
    "- Regularization techniques like Data Augmentation, Dropout, BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "print(model)\n",
    "\n",
    "# get optimizer\n",
    "train_config = TrainingConfiguration()\n",
    "\n",
    "### CHANGE HERE ###\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr = train_config.init_learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train and validate\n",
    "model, train_loss, train_acc, val_loss, val_acc = main(model, optimizer, scheduler=None, data_augmentation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">4.10. Loss and Accuracy Plot</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(train_loss=[train_loss], \n",
    "                   val_loss=[val_loss], \n",
    "                   train_acc=[train_acc], \n",
    "                   val_acc=[val_acc], \n",
    "                   colors=['blue'], \n",
    "                   loss_legend_loc='upper center', \n",
    "                   acc_legend_loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Step 5. Sample Prediction</font><a name=\"step5\"></a>\n",
    "\n",
    "Show some sample predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">5.1. Make Predictions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, device, batch_input):\n",
    "    \n",
    "    data = batch_input.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(data)\n",
    "\n",
    "    # Score to probability using softmax\n",
    "    prob = F.softmax(output, dim=1)\n",
    "\n",
    "    # get the max probability\n",
    "    pred_prob = prob.data.max(dim=1)[0]\n",
    "    \n",
    "    # get the index of the max probability\n",
    "    pred_index = prob.data.max(dim=1)[1]\n",
    "    \n",
    "    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">5.2. Get Predictions on a Batch</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_prediction(model, data_root, mean, std):\n",
    "    batch_size = 15\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        num_workers = 8\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        num_workers = 2\n",
    "    \n",
    "    # It is important to do model.eval() before prediction\n",
    "    model.eval()\n",
    "    \n",
    "    # Send model to cpu/cuda according to your system configuration\n",
    "    model.to(device)\n",
    "\n",
    "    # transformed data\n",
    "    test_dataset_trans = datasets.ImageFolder(root=data_root, transform=image_common_transforms(mean, std))\n",
    "    \n",
    "    # original image dataset\n",
    "    test_dataset = datasets.ImageFolder(root=data_root, transform=image_preprocess_transforms())\n",
    "    \n",
    "    data_len = test_dataset.__len__()\n",
    "    \n",
    "    interval = int(data_len/batch_size)\n",
    "    \n",
    "    imgs = []\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(batch_size):\n",
    "        index = i * interval\n",
    "        trans_input, target = test_dataset_trans.__getitem__(index)\n",
    "        img, _ = test_dataset.__getitem__(index)\n",
    "        \n",
    "        imgs.append(img)\n",
    "        inputs.append(trans_input)\n",
    "        targets.append(target)\n",
    "        \n",
    "    inputs = torch.stack(inputs)\n",
    "        \n",
    "    cls, prob = prediction(model, device, batch_input=inputs)\n",
    "    \n",
    "    plt.style.use('default')\n",
    "    plt.rcParams[\"figure.figsize\"] = (15, 9)\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    \n",
    "    for i, target in enumerate(targets):\n",
    "        plt.subplot(3, 5, i+1)\n",
    "        img = transforms.functional.to_pil_image(imgs[i])\n",
    "        plt.imshow(img)\n",
    "        plt.gca().set_title('P:{0}({1:.2}), T:{2}'.format(test_dataset.classes[cls[i]], \n",
    "                                                     prob[i], \n",
    "                                                     test_dataset.classes[targets[i]]))\n",
    "    fig.savefig('sample_prediction.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">5.3. Load Model and Run Inference</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MyModel()\n",
    "m = load_model(m)\n",
    "\n",
    "train_config = TrainingConfiguration()\n",
    "\n",
    "test_data_path = os.path.join(train_config.data_root, 'validation')\n",
    "train_data_path = os.path.join(train_config.data_root, 'training')\n",
    "\n",
    "mean, std = get_mean_std(train_data_path)\n",
    "\n",
    "get_sample_prediction(m, test_data_path, mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:red\">Step 6. Display Confusion Matrix [10 Points]</font><a name=\"step6\"></a>\n",
    "\n",
    "Display the confusion matrix for the above problem(Refer to the earlier lectures on Performance Metrics).\n",
    "\n",
    "\n",
    "The output should resemble this:\n",
    "\n",
    "<img src='https://www.learnopencv.com/wp-content/uploads/2020/02/c3_w5_sample_confusion_matrix.png' width=600>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon completing the assignment,  <font style=\"color:red\">pload the 2 notebooks and the models folder on the portal for feedback.</font>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

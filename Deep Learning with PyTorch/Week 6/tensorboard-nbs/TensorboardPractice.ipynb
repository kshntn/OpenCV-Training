{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f56285e-7aef-4b84-a3a0-078faa0ca5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import urllib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47d5e43-b43a-4dcd-a6d4-e7d188f5173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13966bc4-07cc-4c90-b2de-0c40e88286d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce845e94-6901-446d-8b44-2ed2de44ae43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8008), started 0:03:30 ago. (Use '!kill 8008' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ee7d169b2ab413e0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ee7d169b2ab413e0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9003c94a-835b-4e5c-a3c1-6237b44376fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'learning'\n",
    "\n",
    "# Directory where logs will be saved. \n",
    "log_dir = os.path.join(logdir, experiment)\n",
    "\n",
    "# initiate tensorboard summary writer\n",
    "tb_writer = SummaryWriter(\n",
    "    log_dir = log_dir,\n",
    "    comment = \"Learning How to use TensorBoard in PyTorch\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff1782c-1dee-401d-9bcb-a88c862d6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_tag = 'accuracy/train'\n",
    "validation_accuracy_tag = 'accuracy/validation'\n",
    "train_loss_tag = 'loss/train'\n",
    "validation_loss_tag = 'loss/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b76a55b6-63bd-44a8-9e8c-653ccfdd4fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_accuracy_generator(iter, iter_divide_by=1):\n",
    "    return 1 - np.exp(-(itr/iter_divide_by + np.random.random()))\n",
    "\n",
    "def dummy_loss_generator(iter, iter_divide_by=1):\n",
    "    return np.exp(-(itr/iter_divide_by + np.random.random()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73ea74c1-74f2-4d99-a791-10e28eedb072",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iteration = 50\n",
    "\n",
    "for itr in range(num_iteration):\n",
    "    tb_writer.add_scalar(tag=train_accuracy_tag, \n",
    "                         scalar_value=dummy_accuracy_generator(itr, 2),\n",
    "                         global_step=itr)\n",
    "    tb_writer.add_scalar(tag=validation_accuracy_tag, \n",
    "                         scalar_value=dummy_accuracy_generator(itr, 3),\n",
    "                         global_step=itr)\n",
    "    tb_writer.add_scalar(tag=train_loss_tag, \n",
    "                         scalar_value=dummy_loss_generator(itr, 2),\n",
    "                         global_step=itr)\n",
    "    tb_writer.add_scalar(tag=validation_loss_tag, \n",
    "                         scalar_value=dummy_loss_generator(itr, 3),\n",
    "                         global_step=itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c07c52c3-eee1-4d31-9e6d-a90d4e45de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tag = 'Accuracy'\n",
    "loss_tag = 'Loss'\n",
    "\n",
    "# Dictionary format to add scalars\n",
    "\n",
    "\"\"\"\n",
    "dic = {\n",
    "    \"Train\": train loss for \"Loss\" tag, train accuracy for \"Accuracy\" tag\n",
    "    \"Validation\": validation loss for \"Loss\" tag, validation accuracy for \"Accuracy\" tag\n",
    "}\n",
    "\"\"\"\n",
    "for itr in range(num_iteration):\n",
    "    tb_writer.add_scalars(main_tag=accuracy_tag, \n",
    "                         tag_scalar_dict={\n",
    "                             \"Train\": dummy_accuracy_generator(itr, 2),\n",
    "                             \"Validation\": dummy_accuracy_generator(itr, 3)\n",
    "                         },\n",
    "                         global_step=itr)\n",
    "    tb_writer.add_scalars(main_tag=loss_tag, \n",
    "                         tag_scalar_dict={\n",
    "                             \"Train\": dummy_loss_generator(itr, 2),\n",
    "                             \"Validation\": dummy_loss_generator(itr, 3)\n",
    "                         },\n",
    "                         global_step=itr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "082a1745-d222-462f-8f49-8a54b243778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls = [\n",
    "    'https://farm7.staticflickr.com/6073/6032446158_85fa667cd2_z.jpg',\n",
    "    'https://farm9.staticflickr.com/8538/8678472399_886f8eabec_z.jpg',\n",
    "    'https://farm6.staticflickr.com/5485/10028794463_d8cbb38932_z.jpg',\n",
    "    'https://farm4.staticflickr.com/3057/2475401198_0a342a907e_z.jpg'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "447abcd2-d41a-465e-afef-20aeb2c46a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images.\n",
    "for i in range(len(image_urls)):\n",
    "    urllib.request.urlretrieve(image_urls[i], \"img{}.jpg\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c34adae-b049-49f8-9a30-23d81825816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Images.\n",
    "num_images = 4\n",
    "\n",
    "images = []\n",
    "for i in range(num_images):\n",
    "    img = cv2.imread('img{}.jpg'.format(i+1))\n",
    "    # BGR to RGB\n",
    "    img = img[...,::-1]\n",
    "    images.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fe89cf8-b9de-493b-8917-9e086d0a4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tag = \"add_image\"\n",
    "\n",
    "for itr in range(num_images):\n",
    "    tb_writer.add_image(tag=image_tag, \n",
    "                        img_tensor=images[itr],\n",
    "                        global_step=itr,\n",
    "                        dataformats='HWC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d36990c-94c4-487f-aade-5ae53dd65108",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_tag = 'Image Hisograms'\n",
    "\n",
    "for itr in range(num_images):\n",
    "    x = np.random.random(1000)\n",
    "    tb_writer.add_histogram(tag=histogram_tag, \n",
    "                            values=images[itr],\n",
    "                            global_step=itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc82a620-6c77-454f-9128-c6c997ef1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "last_epoch = 50\n",
    "sample_count = 1000\n",
    "\n",
    "for i in range(num_classes):\n",
    "    pr_curves_tag = \"class {}\".format(i)\n",
    "    # Generate random labels\n",
    "    labels = np.random.randint(2, size=sample_count)\n",
    "    # Random confidence\n",
    "    predictions = np.random.rand(sample_count)\n",
    "    # add PR curve to tensorboard\n",
    "    tb_writer.add_pr_curve(\n",
    "        tag=pr_curves_tag,\n",
    "        labels=labels,\n",
    "        predictions=predictions,\n",
    "        global_step=last_epoch\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b588c592-95b4-4717-ada5-ce4b7d74d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features size:\ttorch.Size([4, 30000])\n",
      "Images size:\ttorch.Size([4, 3, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "resized_images=[]\n",
    "feature_vectors = []\n",
    "\n",
    "for img in images:\n",
    "    # resize to fix size\n",
    "    resized_img = cv2.resize(img, (100, 100))\n",
    "    # H x W x C --> C x H x W\n",
    "    resized_img = np.moveaxis(resized_img, -1, 0)\n",
    "    feature_vector = np.reshape(resized_img, (-1))\n",
    "    feature_vectors.append(feature_vector)\n",
    "    resized_images.append(resized_img)\n",
    "\n",
    "feature_vectors = np.array(feature_vectors)\n",
    "resized_images = np.array(resized_images)\n",
    "# Convert to torch tensor\n",
    "resized_images = torch.from_numpy(resized_images)\n",
    "feature_vectors = torch.from_numpy(feature_vectors)\n",
    "\n",
    "print('Features size:\\t{}'.format(feature_vectors.size()))\n",
    "print('Images size:\\t{}'.format(resized_images.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e18bd9d9-7a89-49fc-b0bf-0096d09f7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label for each data point\n",
    "labels = ['class 0', 'class 0', 'class 1', 'class 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3e4df23-8144-4f2f-bde6-214debf30fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_tag = 'Embedding'\n",
    "last_epoch = 50\n",
    "\n",
    "tb_writer.add_embedding(mat=feature_vectors,\n",
    "                        metadata=labels, \n",
    "                        label_img=resized_images, \n",
    "                        global_step=last_epoch, \n",
    "                        tag=embedding_tag\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c316be7c-3d18-4399-a860-84ad8f535b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MediumModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.2)\n",
    "            )\n",
    "            \n",
    "        \n",
    "        # Fully connected layers\n",
    "        self._head = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(in_features=64 * 22 * 22, out_features=1024), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(in_features=1024, out_features=512), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(in_features=512, out_features=5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._body(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbea4af2-758d-4568-a927-8d8236114eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MediumModel()\n",
    "# Change the image tensor datatype to float32 to make it compatible with the model.\n",
    "inputs = resized_images.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "591c8b6d-4acb-4893-86b7-d900f4b3f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_writer.add_graph(model=model, \n",
    "                    input_to_model=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616150a-e55a-4593-acab-7c526aa4109c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

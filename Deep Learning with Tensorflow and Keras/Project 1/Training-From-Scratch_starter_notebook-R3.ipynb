{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":72335,"databundleVersionId":7925022,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <font style=\"color:blue\">Project 1 - Part 2: Train an Image Classifier From Scratch</font>\n\n\nAs discussed in the previous notebook, the steps for training Neural Networks are:\n\n\n* Step 1 - Understand your problem\n* Step 2 - Dataset Exploration\n    * Step 2A - Get the data\n    * Step 2B - Explore & understand your data\n    * Step 2C - Create a sample data from the dataset\n* Step 3 - Data preparation\n* Step 4 - Train a simple model on sample data, and check the pipeline before training the full network\n* Step 5 - Train on full data\n* Step 6 - Improve your model\n* Step 7 - Generate Submission file\n\nFollow Steps 1-4 exactly as you did in the previous notebook. Here, you will implement Steps 5, 6 & 7 from scratch.\n\n\n**Design a model that achieves `>=80%` Public Test accuracy on the given dataset.**\n\n\nThis notebook carries **75** points out of a total of **100**. <font style=\"color:red\">The sections which carry marks are in Red.</font>\n\n#### Points Distribution - Maximum Points: 75\n\n\n<div align=\"center\">\n    <table>\n        <tr><td><h3>Number</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n        <tr><td><h3>1</h3></td> <td><h3>Configurations</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>2</h3></td> <td><h3>Model</h3></td> <td><h3>10</h3></td> </tr>\n        <tr><td><h3>3</h3></td> <td><h3>Confusion Matrix</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>4</h3></td> <td><h3>Submission File Generation</h3></td><td><h3>5</h3></td> </tr>\n        <tr><td><h3>5</h3></td> <td><h3>Kaggle Submission Score</h3></td> <td><h3>50</h3></td> </tr>\n    </table>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"**After completing the project, upload and submit the notebook to the lab for feedback.**","metadata":{}},{"cell_type":"markdown","source":"**<font style=\"color:red\">You need to achieve atleast 80% accuracy on the Public test leaderboard to successfully complete this project.</font>**\n\n\n**<font style=\"color:red\">Build your own model from scratch, and do not use any pre-trained models/weights.</font>**","metadata":{}},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Step 1: Understand Your problem </font><a name=\"step1\"></a>\nAlready covered in the previous notebook.","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras.utils import image_dataset_from_directory\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\n\nfrom dataclasses import dataclass\nimport platform\n\n# Text formatting\nbold = \"\\033[1m\"\nend = \"\\033[0m\"\n\nblock_plot=False\n\n%matplotlib inline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font style=\"color:green\">Set Seeds</font>\n\nUse this function to set random seeds for CPU and GPU operations in order to make training deterministic and to ensure reproducibility.","metadata":{}},{"cell_type":"code","source":"def set_seeds():\n    # fix random seeds\n    SEED_VALUE = 42\n\n    random.seed(SEED_VALUE)\n    np.random.seed(SEED_VALUE)\n    tf.random.set_seed(SEED_VALUE)\n    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n    \n    gpus = tf.config.experimental.list_physical_devices('GPU')\n    if gpus:\n        try:\n            # Currently, memory growth needs to be the same across GPUs\n            for gpu in gpus:\n                tf.config.experimental.set_memory_growth(gpu, True)\n        except RuntimeError as e:\n            # Memory growth must be set before GPUs have been initialized\n            print(e)\n    \n#     physical_devices = tf.config.list_physical_devices(\"GPU\")\n#     try:\n#         tf.config.experimental.set_memory_growth(physical_devices[0], True)\n#     except:\n#         # Invalid device or cannot modify virtual devices once initialized.\n#         pass\n\n    return\n\nset_seeds()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a MirroredStrategy for distributed training.\n# This strategy effectively replicates the model's layers on each GPU or other available devices,\n# syncing their weights after each training step.\nDISTRIBUTE_STRATEGY = tf.distribute.MirroredStrategy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Printing the number of devices that are in sync with the MirroredStrategy.\n# This indicates how many replicas of the model are being trained in parallel.\nprint('Number of devices: {}'.format(DISTRIBUTE_STRATEGY.num_replicas_in_sync))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Step 2: Dataset Exploration</font>\n\nAlready covered in the previous notebook.","metadata":{}},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Step 3. Data Preparation</font>\n\nAlready covered in the previous notebook.","metadata":{}},{"cell_type":"code","source":"def get_data(*, data_root, target_size=(224, 224), batch_size=32, data_augmentation=False):\n    ### YOUR CODE HERE\n    ###\n    return","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Step 4: Train Your Model</font>\n\nNow, create the training pipeline and train your model on the full data.","metadata":{}},{"cell_type":"markdown","source":"## <font style=\"color:red\">4.1. Configurations [5 Points]</font>\n\nTo achieve good results, change the parameters given in these configurations.","metadata":{}},{"cell_type":"markdown","source":"### <font style=\"color:green\">4.1.1. Training Configuration</font>","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass TrainingConfig:\n    # Defining the batch size for model training.\n    # The batch size is set to be some integer times the  number of devices in synchronization as per the distributed strategy.\n    # This means that the overall batch of data is divided equally across all the devices used in the distributed training.\n    # By scaling the batch size with the number of replicas (devices), each device processes a batch of size, in this case, 4.\n   \n    # This approach helps in efficient utilization of the computational power of all the devices involved in training.\n    BATCH_SIZE: int = 4 * DISTRIBUTE_STRATEGY.num_replicas_in_sync\n\n    EPOCHS: int = 2\n    LEARNING_RATE: float = 0.1\n\n    # For tensorboard logging and saving checkpoints\n    root_log_dir = os.path.join(\"Logs_Checkpoints\", \"Model_logs\")\n    root_checkpoint_dir = os.path.join(\"Logs_Checkpoints\", \"Model_checkpoints\")\n\n    # Current log and checkpoint directory.\n    log_dir = \"version_0\"\n    checkpoint_initial = \"version_0\"\n\n    # Use multiprocessing during training.\n    use_multiprocessing: bool = True if platform.system() == \"Linux\" else False\n        \n    # Number of workers to use for training.\n    num_workers: int = 4","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font style=\"color:green\">4.1.2. Dataset Configuration</font>","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass DatasetConfig:\n    DATA_ROOT: str = r\"/kaggle/input/opencv-tf-project-1-image-classification-round-3/dataset\"\n    DATA_SHAPE: tuple = (128, 256, 3)\n    NUM_CLASSES: int = 4","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:blue\">4.2. Callbacks</font>\n\nDefine the different callbacks you want to use during training.","metadata":{}},{"cell_type":"code","source":"def get_callbacks(\n    training_config=TrainingConfig(),\n    monitor=\"val_loss\",\n    mode=\"min\",\n    save_weights_only=False,\n    save_best_only=True,\n):\n\n    # Initialize tensorboard callback for logging.\n    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n        log_dir=training_config.log_dir,\n        histogram_freq=20,\n        write_graph=True,\n        update_freq=\"epoch\",\n        write_images=True,\n    )\n\n    \n    checkpoint_filepath = training_config.checkpoint_path\n    \n    # Update file path if saving best model weights.\n    if save_weights_only:\n        checkpoint_filepath = os.path.join(checkpoint_filepath, \"model.ckpt\")\n    else:\n        checkpoint_filepath = os.path.join(checkpoint_filepath, \"model.keras\")\n\n    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_filepath,\n        save_weights_only=save_weights_only,\n        monitor=monitor,\n        mode=mode,\n        save_best_only=save_best_only,\n        verbose=0,\n    )\n    \n    return [tensorboard_callback, model_checkpoint_callback]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:blue\">4.3. Logging Setup</font>\n\nA function for initializing directories so that it saves tensorboard and model checkpoints for different training versions.","metadata":{}},{"cell_type":"code","source":"def setup_log_directory(training_config=TrainingConfig()):\n    '''Tensorboard Log, Model checkpoint directory Setup and Early stopping'''\n    \n    get_number = lambda path: path.replace(\".keras\", \"\").replace(\"version_\", \"\")\n    \n    if os.path.isdir(training_config.root_log_dir):\n        # Get all folders numbers in the root_log_dir\n        folder_numbers = [int(get_number(folder)) for folder in os.listdir(training_config.root_log_dir)]\n        \n        # Find the latest version number present in the log_dir\n        last_version_number = max(folder_numbers)\n\n        # New version name\n        version_name = f\"version_{last_version_number + 1}\"\n\n    else:\n        version_name = training_config.log_dir\n\n\n    # Update the training config default directory \n    training_config.log_dir        = os.path.join(training_config.root_log_dir,        version_name)\n    training_config.checkpoint_path = os.path.join(training_config.root_checkpoint_dir, version_name)\n\n    # Create new directory for saving new experiment version\n    os.makedirs(training_config.log_dir, exist_ok=True)\n    os.makedirs(training_config.root_checkpoint_dir, exist_ok=True)\n\n    print(f\"Logging at: {training_config.log_dir}\")\n    print(f\"Model Checkpoint at: {training_config.checkpoint_path}\")\n    \n    return training_config, version_name","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:blue\">4.4. Plot Loss and Accuracy</font>\n\nUse this function to plot loss and accuracy for training and validation results.","metadata":{}},{"cell_type":"code","source":"def plot_history(\n    train_loss=None,\n    val_loss=None,\n    train_metric=None,\n    val_metric=None,\n    colors=[\"blue\", \"green\"],\n    loss_legend_loc=\"upper center\",\n    acc_legend_loc=\"upper left\",\n    fig_size=(15, 10),\n):\n\n    plt.rcParams[\"figure.figsize\"] = fig_size\n    fig = plt.figure()\n    fig.set_facecolor(\"white\")\n\n    # Loss Plots\n    plt.subplot(2, 1, 1)\n\n    train_loss_range = range(len(train_loss))\n    plt.plot(\n        train_loss_range,\n        train_loss,\n        color=f\"tab:{colors[0]}\",\n        label=f\"Train Loss\",\n    )\n\n    valid_loss_range = range(len(val_loss))\n    plt.plot(\n        valid_loss_range,\n        val_loss,\n        color=f\"tab:{colors[1]}\",\n        label=f\"Valid Loss\",\n    )\n\n    plt.ylabel(\"Loss\")\n    plt.legend(loc=loss_legend_loc)\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n    plt.grid(True)\n    plt.title(\"Training and Validation Loss\")\n\n    # Mean Average Precision Plots\n    plt.subplot(2, 1, 2)\n\n    train_metric_range = range(len(train_metric))\n    plt.plot(\n        train_metric_range,\n        train_metric,\n        color=f\"tab:{colors[0]}\",\n        label=f\"Train Accuracy\",\n    )\n\n    val_metric_range = range(len(val_metric))\n    plt.plot(\n        val_metric_range,\n        val_metric,\n        color=f\"tab:{colors[1]}\",\n        label=f\"Valid Accuracy\",\n    )\n\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n    plt.legend(loc=acc_legend_loc)\n    plt.grid(True)\n    plt.title(\"Training and Validation Accuracy\")\n\n    plt.show(block=block_plot)\n\n    return","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:red\">4.5. Define Model [10 Points]</font>\n\n**Next, define your CNN model.**\n\nKeep iterating. Do this by training various models.\n\nExperiment by changing the:\n\n* Number of layers.\n* Number of filters/units per layer.\n* Different types of layers, e.g., dropout, batch normalization.\n* Different combination of layers.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import Model, Input\nfrom tensorflow.keras.layers import (\n    Conv2D,\n    BatchNormalization,\n    MaxPooling2D,\n    Flatten,\n    Dense,\n    GlobalAveragePooling2D,\n    Rescaling\n)\n\n\n\ndef get_model(num_classes=4, input_shape=(224, 224, 3), name=\"Dummy_Model\"):\n    ### YOUR CODE HERE\n    \n    \n    ### \n    # return your model\n    return\n    \n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:blue\">4.6. Training Pipeline</font>\n\n\nIn this function, we bring together all the different functions we've defined so far.","metadata":{}},{"cell_type":"code","source":"def train_model(\n    dataset_config=DatasetConfig(),\n    training_config=TrainingConfig(),\n    data_augmentation=True,\n    print_summary=True,\n):\n\n    # Get training and validation datasets.\n    train_dataset, valid_dataset = get_data(\n        data_root=dataset_config.DATA_ROOT,\n        target_size=dataset_config.DATA_SHAPE[:2],\n        batch_size=training_config.BATCH_SIZE,\n        data_augmentation=data_augmentation,\n    )\n    \n    for images, labels in valid_dataset:\n        print(\"X Shape:\", images.shape, \"Y Shape:\", labels.shape)\n        break\n        \n\n    # # Get model\n    # model = get_model(num_classes=dataset_config.NUM_CLASSES, input_shape=dataset_config.DATA_SHAPE)\n\n    # # Initialize optimizer\n    # optimizer = tf.keras.optimizers.Adam(learning_rate=training_config.LEARNING_RATE)\n\n    # # Compile model\n    # model.compile(\n    #     loss=\"categorical_crossentropy\",\n    #     optimizer=optimizer,\n    #     metrics=[\"accuracy\"],\n    # )\n\n    # Start a context manager using the distributed strategy previously defined.\n    # This scope ensures that the operations defined within it are distributed across the available devices as per the strategy.\n    with DISTRIBUTE_STRATEGY.scope():\n        # Get the model by calling the 'get_model' function.\n        model = get_model(num_classes=dataset_config.NUM_CLASSES, input_shape=dataset_config.DATA_SHAPE)\n\n        # Compile the model. This step configures the model for training.\n        # 'loss' is set to 'categorical_crossentropy', which is a common choice for classification tasks.\n        # 'optimizer' is an Adam optimizer with a specific learning rate from the training configuration.\n        # 'metrics' is a list of metrics to be evaluated by the model during training and testing, here it's set to track 'accuracy'.\n        model.compile(\n            loss=\"categorical_crossentropy\",\n            optimizer=tf.keras.optimizers.Adam(learning_rate=training_config.LEARNING_RATE),\n            metrics=[\"accuracy\"],\n        )\n\n\n    # Print model summary\n    if print_summary:\n        model.summary()\n\n    # Get training callbacks\n    callbacks = get_callbacks(training_config)\n\n    # Train model\n    training_results = model.fit(\n        train_dataset,\n        validation_data=valid_dataset,\n        epochs=training_config.EPOCHS,\n        callbacks=callbacks,\n        workers=training_config.num_workers,\n        use_multiprocessing=training_config.use_multiprocessing\n    )\n\n    print(\"training_results keys:\", training_results.history.keys())\n\n    return model, training_results","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:blue\">4.7. Training</font>\n\nExperiment with:\n\n- `Optimizers` and `learning rate schedulers`(You can  get good results even without a learning rate scheduler.)\n- Regularization techniques like Data Augmentation, Dropout, BatchNorm.\n- Number of epochs.","metadata":{}},{"cell_type":"code","source":"training_config = TrainingConfig()\n\n# Tensorboard Log and model checkpoint Setup.\ntraining_config, current_version_name = setup_log_directory(training_config)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start training\n\ntrained_model, training_results = train_model(\n    dataset_config=DatasetConfig(),\n    training_config=training_config,\n    data_augmentation=True,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:blue\">4.8. Loss and Accuracy Plot</font>","metadata":{}},{"cell_type":"code","source":"loss = training_results.history[\"loss\"]\naccuracy = training_results.history[\"accuracy\"]\n\nval_loss = training_results.history[\"val_loss\"]\nval_accuracy = training_results.history[\"val_accuracy\"]\n\nplot_history(\n    train_loss=loss,\n    train_metric=accuracy,\n    val_loss=val_loss,\n    val_metric=val_accuracy,\n    loss_legend_loc=\"upper center\",\n    acc_legend_loc=\"upper left\",\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Step 5: Sample Prediction</font>\n\nShow some sample predictions.","metadata":{}},{"cell_type":"markdown","source":"## <font style=\"color:blue\">5.1. Reload the Model</font>\n\nA function to help reload the model or the weights saved during training.","metadata":{}},{"cell_type":"code","source":"def recreate_model(path, load_weights=False, config=DatasetConfig(), **kwargs):\n    \"\"\"\n    For reloading trained model\n    Args:\n        path: current_version checkpoint path\n        load_weights: Whether the files saved at path contains model weights\n                      or the Entire model configuration\n        **kwargs: use to pass additional keyword arguments to the load_model method\n    Returns:\n        Reinitialized Trained Model\n    \"\"\"\n\n    if load_weights:\n        \n        # Create model architecture\n        model = get_model(num_classes=config.NUM_CLASSES, input_shape=config.DATA_SHAPE)\n\n        # Load trained model best weights.\n        path = os.path.join(path, \"model.ckpt\")\n        model.load_weights(path).expect_partial()\n    else:\n        path = os.path.join(path, \"model.keras\")\n        model = tf.keras.models.load_model(path, **kwargs)\n\n    model.summary()\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font style=\"color:green\">Loading latest trained model version</font>","metadata":{}},{"cell_type":"code","source":"load_version = current_version_name\ncheckpoint_path = os.path.join(training_config.root_checkpoint_dir, load_version) \n\ntrained_model = recreate_model(checkpoint_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:blue\">5.2. Running Inference</font>\n\nWe’ll be running dummy inference on validation data, and displaying 15 images.","metadata":{}},{"cell_type":"code","source":"def get_sample_predictions(*, model, dataset, total=15):\n\n    imgs = []\n    ground_truths = []\n    probs = []\n    predictions = []\n\n    idx_to_cls = {0: \"cow\", 1: \"elephant\", 2: \"horse\", 3: \"spider\"}\n\n    print(\"Generating Predictions...\")\n    for data, target in dataset:\n        model_predictions = model.predict_on_batch(data)\n        cls_predicted = np.argmax(model_predictions, axis=-1)\n        cls_probs = np.max(model_predictions, axis=-1)\n    \n        imgs.extend(data.numpy() / 255.)\n        ground_truths.extend(target.numpy())\n        predictions.extend(cls_predicted)\n        probs.extend(cls_probs)\n        \n        # Displaying only 15 images \n        if data.shape[0] >= total: \n            break\n\n    plt.style.use(\"default\")\n    plt.rcParams[\"figure.figsize\"] = (18, 9)\n    fig = plt.figure()\n    fig.set_facecolor(\"white\")\n\n    for idx in range(total):\n\n        plt.subplot(3, 5, idx + 1)\n        img = imgs[idx]\n        plt.imshow(img)\n\n        plt.title(f\"P:{idx_to_cls[predictions[idx]]}({probs[idx]:.2}), T:{idx_to_cls[ground_truths[idx]]}\")\n        plt.axis(\"off\")\n\n    fig.savefig(\"sample_predictions.png\")\n    plt.show(block=block_plot)\n    \n    del imgs, ground_truths, probs, predictions\n    return","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_config = DatasetConfig()\ntraining_config = TrainingConfig()\n\nvalid_path = os.path.join(data_config.DATA_ROOT, \"Valid\")\n\nvalid_dataset = tf.keras.utils.image_dataset_from_directory(\n    valid_path, \n    label_mode='int',\n    color_mode='rgb', \n    batch_size=training_config.BATCH_SIZE, \n    image_size=data_config.DATA_SHAPE[:2], \n    shuffle=True, # shuffling to show images from all classes\n)\n\nget_sample_predictions(model=trained_model, dataset=valid_dataset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:red\">Step 6. Display Confusion Matrix [5 Points]</font>\n\nDisplay the confusion matrix (Refer to the earlier lectures on Performance Metrics for this).\n\n\nThis is what the output should look like:\n\n<img src='https://learnopencv.com/wp-content/uploads/2022/02/c4_project_a1_confusion_matrix.png' width=600>\n","metadata":{}},{"cell_type":"code","source":"### YOUR CODE HERE\n    \n    \n###","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:red\">Step 7. Generate Submission File [5 Points]</font>\n\n\n**TASK**\n\n1. Generate predictions on the test set.\n2. Create a submission `.csv` file.\n3. Upload the `.csv` file on Kaggle.\n\n\n**REFERENCE**\n1. **`test.csv`** -  This CSV file contains image IDs for the test set. Read this CSV file to generate predictions for each test image.\n\n2. **`sample_submission.csv`** - Refer to this file to understand the structure of the csv file to be submitted. The sample_submission file is only to be used as reference. <br>\nIt contains columns:\n    1. **`ID`**: same as the test.csv file\n    2. **`CLASS`**: which contains random predictions\n\n\n\n\n**<font style=\"color:red\">Use the same column names that are given in the`sample_submission.csv` file.</font>**\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n\n### YOUR CODE HERE\n    \n###","metadata":{"execution":{"iopub.status.busy":"2024-03-12T07:29:07.773856Z","iopub.execute_input":"2024-03-12T07:29:07.774128Z","iopub.status.idle":"2024-03-12T07:29:08.068481Z","shell.execute_reply.started":"2024-03-12T07:29:07.774107Z","shell.execute_reply":"2024-03-12T07:29:08.067699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:red\">Step 8. Kaggle Submission Score [50 Points]</font>\n\n**For full points, you need to achieve atleast `85%` accuracy on the Public Test leaderboard. If accuracy is less than `80%`, you gain no points for this section.**\n\n\n**Submit `submission.csv` (prediction for images in `test.csv`), in the `Submit Predictions` tab in Kaggle, in order to get evaluated for this section.**","metadata":{}},{"cell_type":"markdown","source":"**Please share your profile link, user id and score achieved.**\n\n```\nURL:\nProfile Name:\nPoints Scored:\n```","metadata":{}},{"cell_type":"markdown","source":"**Upon completing the project, <font style=\"color:red\">upload the notebook to the lab for grading and feedback.</font>**","metadata":{}},{"cell_type":"markdown","source":"**<font style=\"color:red\">Please do not make your notebooks public or publish them on the competition page. You only need to submit your notebook to the lab. This is to make sure that students don't copy each other.</font>**","metadata":{}}]}